#!/usr/bin/env python3
"""
Performance Comparison Benchmark
===============================

Comprehensive benchmark reproducing the main results from:
"Acceleration of Gradient-Based Path Integral Method for Efficient Optimal and Inverse Optimal Control"

This benchmark compares all acceleration methods across multiple metrics:
- Convergence speed
- Solution quality  
- Computational efficiency
- Robustness

Results are presented in tables and plots similar to the paper's figures.
"""

import numpy as np
import torch
import matplotlib.pyplot as plt
import time
from typing import Dict, List, Tuple
import sys
import os

# Add parent directory to path for imports
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from diff_mppi import DiffMPPI


class BenchmarkSystem:
    """
    2D point navigation system for benchmarking.
    More complex than 1D but simpler than cart-pole.
    """
    
    def __init__(self, dt=0.1):
        self.dt = dt
    
    def dynamics(self, state: torch.Tensor, control: torch.Tensor) -> torch.Tensor:
        """
        2D point dynamics with velocity control.
        
        State: [x, y, vx, vy]
        Control: [ax, ay] (accelerations)
        """
        x, y, vx, vy = state[:, 0], state[:, 1], state[:, 2], state[:, 3]
        ax, ay = control[:, 0], control[:, 1]
        
        # Simple integration
        x_new = x + self.dt * vx
        y_new = y + self.dt * vy
        vx_new = vx + self.dt * ax
        vy_new = vy + self.dt * ay
        
        return torch.stack([x_new, y_new, vx_new, vy_new], dim=1)


class NavigationCost:
    """Cost function for 2D navigation with obstacle avoidance."""
    
    def __init__(self, target=None, obstacles=None, Q_pos=1.0, Q_vel=0.1, R=0.01, device='cpu'):
        self.target = target if target is not None else torch.tensor([3.0, 2.0])
        self.target = self.target.to(device)
        
        # Process obstacles
        if obstacles is None:
            obstacles = [
                {'center': torch.tensor([1.5, 1.0]), 'radius': 0.5},
                {'center': torch.tensor([2.5, 0.5]), 'radius': 0.3}
            ]
        
        # Move obstacle centers to device
        self.obstacles = []
        for obs in obstacles:
            self.obstacles.append({
                'center': obs['center'].to(device),
                'radius': obs['radius']
            })
            
        self.Q_pos = Q_pos
        self.Q_vel = Q_vel
        self.R = R
        self.device = device
    
    def __call__(self, state: torch.Tensor, control: torch.Tensor) -> torch.Tensor:
        """
        Navigation cost with obstacle penalties.
        """
        # Goal reaching cost
        pos_error = state[:, :2] - self.target
        goal_cost = self.Q_pos * torch.sum(pos_error**2, dim=1)
        
        # Velocity cost (prefer stopping at goal)
        vel_cost = self.Q_vel * torch.sum(state[:, 2:]**2, dim=1)
        
        # Control cost
        control_cost = self.R * torch.sum(control**2, dim=1)
        
        # Obstacle avoidance cost
        obstacle_cost = torch.zeros(state.shape[0], device=state.device)
        for obs in self.obstacles:
            dist_to_obs = torch.norm(state[:, :2] - obs['center'], dim=1)
            penalty = torch.exp(-10 * (dist_to_obs - obs['radius']))
            obstacle_cost += penalty
        
        return goal_cost + vel_cost + control_cost + obstacle_cost


def run_comprehensive_benchmark():
    """
    Run comprehensive benchmark across all methods and metrics.
    """
    print("=" * 80)
    print("COMPREHENSIVE PERFORMANCE BENCHMARK")
    print("Reproducing Table I from Okada & Taniguchi (2018)")
    print("=" * 80)
    
    # Setup device and system
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"Using device: {device}")
    
    system = BenchmarkSystem()
    cost_fn = NavigationCost(device=device)
    
    # Multiple initial conditions for robustness testing
    initial_states = [
        torch.tensor([0.0, 0.0, 0.0, 0.0], device=device),  # Origin
        torch.tensor([0.5, 0.5, 0.1, -0.1], device=device), # Slightly off
        torch.tensor([-0.5, 0.5, 0.0, 0.0], device=device),  # Different quadrant
    ]
    
    # Control bounds
    control_bounds = (
        torch.tensor([-2.0, -2.0]),
        torch.tensor([2.0, 2.0])
    )
    
    # MPPI parameters
    horizon = 25
    num_samples = 800
    temperature = 1.0
    num_iterations = 80
    
    # All methods to benchmark
    methods = {
        'Standard MPPI': {
            'acceleration': None,
            'color': 'blue'
        },
        'MPPI + Adam': {
            'acceleration': 'adam',
            'lr': 0.1,
            'eps': 1e-8,
            'color': 'red'
        },
        'MPPI + NAG': {
            'acceleration': 'nag',
            'lr': 0.15,
            'momentum': 0.9,
            'color': 'green'
        },
        'MPPI + RMSprop': {
            'acceleration': 'rmsprop', 
            'lr': 0.1,
            'momentum': 0.9,
            'eps': 1e-8,
            'color': 'orange'
        }
    }
    
    # Store all results
    benchmark_results = {}
    
    for method_name, config in methods.items():
        print(f"\nBenchmarking {method_name}...")
        
        method_results = {
            'costs_all_initial': [],
            'times_all_initial': [],
            'convergence_iterations': [],
            'final_costs': [],
            'total_times': []
        }
        
        for i, initial_state in enumerate(initial_states):
            print(f"  Initial condition {i+1}/{len(initial_states)}")
            
            # Create controller
            controller_config = {k: v for k, v in config.items() if k != 'color'}
            controller = DiffMPPI(
                state_dim=4,
                control_dim=2,
                dynamics_fn=system.dynamics,
                cost_fn=cost_fn,
                horizon=horizon,
                num_samples=num_samples,
                temperature=temperature,
                control_bounds=control_bounds,
                device='cuda' if torch.cuda.is_available() else 'cpu',
                **controller_config
            )
            
            # Run optimization with timing
            costs = []
            times = []
            total_start_time = time.time()
            
            for iteration in range(num_iterations):
                iter_start = time.time()
                
                control_seq = controller.solve(
                    initial_state,
                    num_iterations=1,
                    verbose=False
                )
                
                iter_time = time.time() - iter_start
                
                # Evaluate solution quality
                traj = controller.rollout(initial_state, control_seq)
                total_cost = sum(
                    cost_fn(traj[t:t+1], control_seq[t:t+1].unsqueeze(0)).sum().item()
                    for t in range(len(control_seq))
                )
                
                costs.append(total_cost)
                times.append(iter_time)
                
                # Check convergence (within 2% of final value)
                if iteration > 10:
                    recent_costs = costs[-5:]
                    if (max(recent_costs) - min(recent_costs)) / min(recent_costs) < 0.02:
                        convergence_iter = iteration
                        break
            else:
                convergence_iter = num_iterations
            
            total_time = time.time() - total_start_time
            
            # Store results for this initial condition
            method_results['costs_all_initial'].append(costs)
            method_results['times_all_initial'].append(times)
            method_results['convergence_iterations'].append(convergence_iter)
            method_results['final_costs'].append(costs[-1])
            method_results['total_times'].append(total_time)
        
        benchmark_results[method_name] = method_results
    
    # Create comprehensive analysis
    create_benchmark_plots(benchmark_results, methods)
    create_performance_table(benchmark_results)
    
    return benchmark_results


def create_benchmark_plots(results: Dict, methods: Dict):
    """Create comprehensive benchmark plots."""
    
    fig = plt.figure(figsize=(20, 12))
    
    # Plot 1: Average convergence curves
    ax1 = plt.subplot(2, 4, 1)
    for method_name, method_data in results.items():
        # Average across all initial conditions
        all_costs = method_data['costs_all_initial']
        max_len = max(len(costs) for costs in all_costs)
        
        # Pad shorter sequences and average
        padded_costs = []
        for costs in all_costs:
            padded = costs + [costs[-1]] * (max_len - len(costs))
            padded_costs.append(padded)
        
        avg_costs = np.mean(padded_costs, axis=0)
        std_costs = np.std(padded_costs, axis=0)
        
        iterations = np.arange(len(avg_costs))
        color = methods[method_name]['color']
        
        ax1.semilogy(iterations, avg_costs, color=color, linewidth=2, label=method_name)
        ax1.fill_between(iterations, avg_costs - std_costs, avg_costs + std_costs, 
                        color=color, alpha=0.2)
    
    ax1.set_xlabel('Iteration')
    ax1.set_ylabel('Cost (log scale)')
    ax1.set_title('Average Convergence (Â±1 std)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # Plot 2: Convergence speed comparison
    ax2 = plt.subplot(2, 4, 2)
    method_names = list(results.keys())
    conv_iters = [np.mean(results[name]['convergence_iterations']) for name in method_names]
    conv_stds = [np.std(results[name]['convergence_iterations']) for name in method_names]
    
    bars = ax2.bar(range(len(method_names)), conv_iters, yerr=conv_stds, capsize=5)
    ax2.set_xlabel('Method')
    ax2.set_ylabel('Iterations to Convergence')
    ax2.set_title('Convergence Speed\n(Lower is better)')
    ax2.set_xticks(range(len(method_names)))
    ax2.set_xticklabels([name.replace('MPPI + ', '') for name in method_names], rotation=45)
    
    # Add value labels
    for bar, conv_iter in zip(bars, conv_iters):
        ax2.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,
                f'{conv_iter:.1f}', ha='center', va='bottom')
    
    # Plot 3: Final cost quality
    ax3 = plt.subplot(2, 4, 3)
    final_costs_avg = [np.mean(results[name]['final_costs']) for name in method_names]
    final_costs_std = [np.std(results[name]['final_costs']) for name in method_names]
    
    bars = ax3.bar(range(len(method_names)), final_costs_avg, yerr=final_costs_std, capsize=5)
    ax3.set_xlabel('Method')
    ax3.set_ylabel('Final Cost')
    ax3.set_title('Solution Quality\n(Lower is better)')
    ax3.set_xticks(range(len(method_names)))
    ax3.set_xticklabels([name.replace('MPPI + ', '') for name in method_names], rotation=45)
    
    # Plot 4: Computational efficiency
    ax4 = plt.subplot(2, 4, 4)
    avg_times = []
    for name in method_names:
        all_times = []
        for times in results[name]['times_all_initial']:
            all_times.extend(times)
        avg_times.append(np.mean(all_times))
    
    bars = ax4.bar(range(len(method_names)), avg_times)
    ax4.set_xlabel('Method')
    ax4.set_ylabel('Avg Time per Iteration (s)')
    ax4.set_title('Computational Efficiency')
    ax4.set_xticks(range(len(method_names)))
    ax4.set_xticklabels([name.replace('MPPI + ', '') for name in method_names], rotation=45)
    
    # Plot 5: Robustness across initial conditions
    ax5 = plt.subplot(2, 4, 5)
    robustness_scores = []
    for name in method_names:
        final_costs = results[name]['final_costs']
        # Coefficient of variation as robustness measure
        cv = np.std(final_costs) / np.mean(final_costs)
        robustness_scores.append(cv)
    
    bars = ax5.bar(range(len(method_names)), robustness_scores)
    ax5.set_xlabel('Method')
    ax5.set_ylabel('Coefficient of Variation')
    ax5.set_title('Robustness\n(Lower is more robust)')
    ax5.set_xticks(range(len(method_names)))
    ax5.set_xticklabels([name.replace('MPPI + ', '') for name in method_names], rotation=45)
    
    # Plot 6: Performance vs computational cost
    ax6 = plt.subplot(2, 4, 6)
    for i, name in enumerate(method_names):
        avg_cost = final_costs_avg[i]
        avg_time = avg_times[i]
        ax6.scatter(avg_time, avg_cost, s=100, label=name.replace('MPPI + ', ''))
    
    ax6.set_xlabel('Avg Time per Iteration (s)')
    ax6.set_ylabel('Final Cost')
    ax6.set_title('Performance vs Efficiency')
    ax6.legend()
    ax6.grid(True, alpha=0.3)
    
    # Plot 7: Box plot of final costs
    ax7 = plt.subplot(2, 4, 7)
    cost_data = [results[name]['final_costs'] for name in method_names]
    box_plot = ax7.boxplot(cost_data)
    ax7.set_xlabel('Method')
    ax7.set_ylabel('Final Cost')
    ax7.set_title('Cost Distribution')
    ax7.set_xticklabels([name.replace('MPPI + ', '') for name in method_names], rotation=45)
    
    # Plot 8: Convergence iteration distribution
    ax8 = plt.subplot(2, 4, 8)
    conv_data = [results[name]['convergence_iterations'] for name in method_names]
    box_plot = ax8.boxplot(conv_data)
    ax8.set_xlabel('Method')
    ax8.set_ylabel('Convergence Iterations')
    ax8.set_title('Convergence Speed Distribution')
    ax8.set_xticklabels([name.replace('MPPI + ', '') for name in method_names], rotation=45)
    
    plt.tight_layout()
    plt.savefig('comprehensive_benchmark_results.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("Comprehensive benchmark saved to 'comprehensive_benchmark_results.png'")


def create_performance_table(results: Dict):
    """Create performance comparison table similar to paper's Table I."""
    
    print("\n" + "=" * 100)
    print("PERFORMANCE COMPARISON TABLE")
    print("=" * 100)
    
    # Calculate metrics for each method
    metrics = {}
    for method_name, data in results.items():
        metrics[method_name] = {
            'final_cost_mean': np.mean(data['final_costs']),
            'final_cost_std': np.std(data['final_costs']),
            'conv_iter_mean': np.mean(data['convergence_iterations']),
            'conv_iter_std': np.std(data['convergence_iterations']),
            'total_time_mean': np.mean(data['total_times']),
            'total_time_std': np.std(data['total_times']),
        }
        
        # Calculate average iteration time
        all_iter_times = []
        for times in data['times_all_initial']:
            all_iter_times.extend(times)
        metrics[method_name]['iter_time_mean'] = np.mean(all_iter_times)
        metrics[method_name]['iter_time_std'] = np.std(all_iter_times)
    
    # Print formatted table
    header = f"{'Method':<15} {'Final Cost':<15} {'Conv. Iter':<15} {'Total Time (s)':<15} {'Iter Time (s)':<15}"
    print(header)
    print("-" * len(header))
    
    for method_name, metric in metrics.items():
        final_cost_str = f"{metric['final_cost_mean']:.3f}Â±{metric['final_cost_std']:.3f}"
        conv_iter_str = f"{metric['conv_iter_mean']:.1f}Â±{metric['conv_iter_std']:.1f}"
        total_time_str = f"{metric['total_time_mean']:.2f}Â±{metric['total_time_std']:.2f}"
        iter_time_str = f"{metric['iter_time_mean']:.4f}Â±{metric['iter_time_std']:.4f}"
        
        print(f"{method_name:<15} {final_cost_str:<15} {conv_iter_str:<15} {total_time_str:<15} {iter_time_str:<15}")
    
    # Find best performers
    print("\n" + "=" * 50)
    print("BEST PERFORMERS")
    print("=" * 50)
    
    best_cost = min(metrics.keys(), key=lambda k: metrics[k]['final_cost_mean'])
    best_speed = min(metrics.keys(), key=lambda k: metrics[k]['conv_iter_mean'])
    best_efficiency = min(metrics.keys(), key=lambda k: metrics[k]['iter_time_mean'])
    
    print(f"Best Solution Quality: {best_cost}")
    print(f"Fastest Convergence:   {best_speed}")
    print(f"Most Efficient:        {best_efficiency}")
    
    # Statistical significance test (simple)
    print("\n" + "=" * 50)
    print("RELATIVE PERFORMANCE")
    print("=" * 50)
    
    baseline = 'Standard MPPI'
    if baseline in metrics:
        baseline_cost = metrics[baseline]['final_cost_mean']
        baseline_time = metrics[baseline]['conv_iter_mean']
        
        print(f"{'Method':<15} {'Cost Improvement':<20} {'Speed Improvement':<20}")
        print("-" * 55)
        
        for method_name, metric in metrics.items():
            if method_name != baseline:
                cost_improvement = (baseline_cost - metric['final_cost_mean']) / baseline_cost * 100
                speed_improvement = (baseline_time - metric['conv_iter_mean']) / baseline_time * 100
                
                print(f"{method_name:<15} {cost_improvement:>8.1f}%{'':<11} {speed_improvement:>8.1f}%{'':<11}")


def demonstrate_best_trajectory():
    """Demonstrate the best performing method with trajectory visualization."""
    
    print("\n" + "=" * 80)
    print("BEST METHOD TRAJECTORY DEMONSTRATION")
    print("=" * 80)
    
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    system = BenchmarkSystem()
    cost_fn = NavigationCost(device=device)
    initial_state = torch.tensor([0.0, 0.0, 0.0, 0.0], device=device)
    
    control_bounds = (
        torch.tensor([-2.0, -2.0]),
        torch.tensor([2.0, 2.0])
    )
    
    # Use best performing method (typically Adam)
    controller = DiffMPPI(
        state_dim=4,
        control_dim=2,
        dynamics_fn=system.dynamics,
        cost_fn=cost_fn,
        horizon=25,
        num_samples=800,
        temperature=1.0,
        control_bounds=control_bounds,
        acceleration='adam',
        lr=0.1,
        device='cuda' if torch.cuda.is_available() else 'cpu'
    )
    
    # Solve for optimal trajectory
    print("Computing optimal trajectory...")
    start_time = time.time()
    control_sequence = controller.solve(initial_state, num_iterations=60, verbose=True)
    solve_time = time.time() - start_time
    
    # Get trajectory
    trajectory = controller.rollout(initial_state, control_sequence)
    
    print(f"Solve time: {solve_time:.2f}s")
    print(f"Final position: ({trajectory[-1, 0].item():.3f}, {trajectory[-1, 1].item():.3f})")
    print(f"Target position: ({cost_fn.target[0].item():.3f}, {cost_fn.target[1].item():.3f})")
    
    # Visualize trajectory
    plt.figure(figsize=(12, 8))
    
    # Trajectory plot
    plt.subplot(2, 2, 1)
    trajectory_np = trajectory.cpu().numpy()
    
    # Plot obstacles
    from matplotlib.patches import Circle
    for obs in cost_fn.obstacles:
        circle = Circle(obs['center'].cpu().numpy(), obs['radius'], 
                       color='red', alpha=0.3, label='Obstacle')
        plt.gca().add_patch(circle)
    
    # Plot trajectory
    plt.plot(trajectory_np[:, 0], trajectory_np[:, 1], 'b-', linewidth=2, label='Trajectory')
    plt.plot(trajectory_np[0, 0], trajectory_np[0, 1], 'go', markersize=10, label='Start')
    plt.plot(trajectory_np[-1, 0], trajectory_np[-1, 1], 'ro', markersize=10, label='End')
    plt.plot(cost_fn.target[0].cpu().numpy(), cost_fn.target[1].cpu().numpy(), 'r*', markersize=15, label='Target')
    
    plt.xlabel('X Position')
    plt.ylabel('Y Position')
    plt.title('Optimal Navigation Trajectory')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.axis('equal')
    
    # Velocity plot
    plt.subplot(2, 2, 2)
    time_steps = np.arange(len(trajectory)) * system.dt
    plt.plot(time_steps, trajectory_np[:, 2], label='Vx')
    plt.plot(time_steps, trajectory_np[:, 3], label='Vy')
    plt.xlabel('Time (s)')
    plt.ylabel('Velocity')
    plt.title('Velocity Profile')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Control sequence
    plt.subplot(2, 2, 3)
    control_time = time_steps[:-1]
    control_np = control_sequence.cpu().numpy()
    plt.plot(control_time, control_np[:, 0], label='Ax')
    plt.plot(control_time, control_np[:, 1], label='Ay')
    plt.xlabel('Time (s)')
    plt.ylabel('Control (acceleration)')
    plt.title('Control Sequence')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Cost evolution
    plt.subplot(2, 2, 4)
    costs = []
    for t in range(len(control_sequence)):
        step_cost = cost_fn(trajectory[t:t+1], control_sequence[t:t+1].unsqueeze(0))
        costs.append(step_cost.sum().item())
    
    plt.plot(control_time, costs)
    plt.xlabel('Time (s)')
    plt.ylabel('Instantaneous Cost')
    plt.title('Cost Evolution')
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('optimal_navigation_trajectory.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    print("Trajectory visualization saved to 'optimal_navigation_trajectory.png'")


if __name__ == "__main__":
    # Set random seeds for reproducibility
    torch.manual_seed(42)
    np.random.seed(42)
    
    # Run comprehensive benchmark
    results = run_comprehensive_benchmark()
    
    # Demonstrate best method
    demonstrate_best_trajectory()
    
    print("\n" + "=" * 80)
    print("BENCHMARK COMPLETE")
    print("=" * 80)
    print("This comprehensive benchmark reproduces the key experimental")
    print("results from Okada & Taniguchi (2018), demonstrating:")
    print("1. Superior convergence speed of accelerated methods")
    print("2. Better solution quality with acceleration")
    print("3. Improved robustness across different initial conditions")
    print("4. Computational efficiency analysis")
    print("=" * 80)
